# ==================================================
# HEALTHAI - FINAL STABLE MULTILINGUAL CLINICAL AI SYSTEM
# ==================================================
import streamlit as st
import numpy as np
import pandas as pd
import os
from dotenv import load_dotenv
import json
import pickle
import base64
import tensorflow as tf
from tensorflow import keras

# ==================================================
# ENV + PAGE
# ==================================================
load_dotenv()
API_KEY = os.getenv("GROQ_API_KEY")

st.set_page_config(page_title="HealthAI", layout="wide")
st.title("ðŸ§  HealthAI - Multilingual Clinical AI System")
st.caption("Clinical ML * Imaging AI * Medical RAG * Sentiment * Translator")

# ==================================================
# MODEL LOADING (WITH GRACEFUL FALLBACK)
# ==================================================
MODELS = {}
MODEL_STATUS = {}
MODELS_DIR = "models"

@st.cache_resource
def load_models():
Â  Â  """Load ML models with error handling"""
Â  Â  status = {}
Â  Â Â 
Â  Â  # List of expected model files
Â  Â  expected_models = {
Â  Â  Â  Â  "xgboost_disease_model.json": "XGBoost Disease Model",
Â  Â  Â  Â  "association_rules.json": "Association Rules",
Â  Â  Â  Â  "los_scaler.pkl": "LOS Scaler",
Â  Â  Â  Â  "kmeans_cluster_model.pkl": "KMeans Clustering",
Â  Â  Â  Â  "cluster_scaler_final.pkl": "Cluster Scaler"
Â  Â  }
Â  Â Â 
Â  Â  for model_file, model_name in expected_models.items():
Â  Â  Â  Â  model_path = os.path.join(MODELS_DIR, model_file)
Â  Â  Â  Â  try:
Â  Â  Â  Â  Â  Â  if os.path.exists(model_path):
Â  Â  Â  Â  Â  Â  Â  Â  if model_file.endswith('.json'):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  with open(model_path, 'r') as f:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  MODELS[model_name] = json.load(f)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  status[model_name] = "âœ“ Loaded"
Â  Â  Â  Â  Â  Â  Â  Â  elif model_file.endswith('.pkl'):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  with open(model_path, 'rb') as f:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  MODELS[model_name] = pickle.load(f)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  status[model_name] = "âœ“ Loaded"
Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  status[model_name] = "âœ— Not found"
Â  Â  Â  Â  except Exception as e:
Â  Â  Â  Â  Â  Â  status[model_name] = f"ERROR: {str(e)[:30]}"
Â  Â Â 
Â  Â  return status

# Load models on startup
MODEL_STATUS = load_models()

if not API_KEY:
Â  Â  st.warning("GROQ_API_KEY not configured. Some features will be limited.")
else:
Â  Â  from groq import Groq
Â  Â  client = Groq(api_key=API_KEY)

# ==================================================
# UI TABS
# ==================================================
tabs = st.tabs([
Â  Â  "Clinical Assessment",
Â  Â  "Imaging Diagnosis",
Â  Â  "Medical RAG",
Â  Â  "Sentiment",
Â  Â  "Translator",
Â  Â  "About"
])

# ==================================================
# TAB 0 - CLINICAL ASSESSMENT
# ==================================================
with tabs[0]:
Â  Â  st.subheader("Patient Clinical Assessment")
Â  Â  st.write("Enter patient vitals to assess disease risk.")
Â  Â Â 
Â  Â  with st.form("clinical_form"):
Â  Â  Â  Â  c1, c2 = st.columns(2)
Â  Â  Â  Â  with c1:
Â  Â  Â  Â  Â  Â  age = st.number_input("Age", 1, 120, 50)
Â  Â  Â  Â  Â  Â  gender = st.selectbox("Gender", ["Male", "Female"])
Â  Â  Â  Â  Â  Â  bmi = st.number_input("BMI", 10.0, 60.0, 25.0)
Â  Â  Â  Â  Â  Â  hr = st.number_input("Heart Rate", 40, 150, 80)
Â  Â  Â  Â  with c2:
Â  Â  Â  Â  Â  Â  sbp = st.number_input("Systolic BP", 80, 250, 120)
Â  Â  Â  Â  Â  Â  dbp = st.number_input("Diastolic BP", 40, 150, 80)
Â  Â  Â  Â  Â  Â  sugar = st.number_input("Blood Sugar", 50, 400, 110)
Â  Â  Â  Â  Â  Â  chol = st.number_input("Cholesterol", 100, 400, 180)
Â  Â  Â  Â Â 
Â  Â  Â  Â  analyze = st.form_submit_button("Analyze")
Â  Â Â 
Â  Â  if analyze:
Â  Â  Â  Â  if sbp >= 140 or sugar >= 126:
Â  Â  Â  Â  Â  Â  risk, color = "HIGH", "red"
Â  Â  Â  Â  elif bmi >= 25 or sbp >= 130:
Â  Â  Â  Â  Â  Â  risk, color = "MEDIUM", "orange"
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  risk, color = "LOW", "green"
Â  Â  Â  Â Â 
Â  Â  Â  Â  st.markdown("---")
Â  Â  Â  Â  st.subheader("Clinical Assessment Results")
Â  Â  Â  Â  st.markdown(f"**Disease Risk: {risk}**")
Â  Â  Â  Â Â 
Â  Â  Â  Â  if risk == "LOW":
Â  Â  Â  Â  Â  Â  st.success("Low risk patient")
Â  Â  Â  Â  elif risk == "MEDIUM":
Â  Â  Â  Â  Â  Â  st.warning("Moderate risk - monitoring recommended")
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  st.error("High risk - clinical attention required")
Â  Â  Â  Â Â 
Â  Â  Â  Â  c1, c2, c3 = st.columns(3)
Â  Â  Â  Â  with c1:
Â  Â  Â  Â  Â  Â  st.metric("Age Group", "Adult" if age >= 18 else "Minor")
Â  Â  Â  Â  with c2:
Â  Â  Â  Â  Â  Â  bmi_cat = "Normal" if bmi < 25 else "Overweight" if bmi < 30 else "Obese"
Â  Â  Â  Â  Â  Â  st.metric("BMI Category", bmi_cat)
Â  Â  Â  Â  with c3:
Â  Â  Â  Â  Â  Â  st.metric("Risk Level", risk)

# ==================================================
# TAB 1 - IMAGING DIAGNOSIS
# ==================================================
with tabs[1]:
Â  Â  st.subheader("Medical Image Analysis with Vision Language Model")
Â  Â  st.write("Upload medical images for AI analysis using Groq VLM.")
Â  Â Â 
Â  Â  uploaded_file = st.file_uploader("Upload Medical Image", type=["jpg", "png", "jpeg"])
Â  Â Â 
Â  Â  if uploaded_file is not None:
Â  Â  Â  Â  from PIL import Image
Â  Â  Â  Â  image = Image.open(uploaded_file)
Â  Â  Â  Â  st.image(image, caption="Uploaded Medical Image", width=400)
Â  Â  Â  Â Â 
Â  Â  Â  Â  if not API_KEY:
Â  Â  Â  Â  Â  Â  st.warning("Configure GROQ_API_KEY to enable VLM analysis.")
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  if st.button("Analyze Image with Groq VLM"):
Â  Â  Â  Â  Â  Â  Â  Â  with st.spinner("Analyzing image..."):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  try:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  image_data = image.convert('RGB')
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  import io
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  img_byte_arr = io.BytesIO()
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  image_data.save(img_byte_arr, format='JPEG')
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  img_byte_arr.seek(0)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  base64_image = base64.b64encode(img_byte_arr.read()).decode('utf-8')
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  message = client.chat.completions.create(
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  model="meta-llama/llama-4-scout-17b-16e-instruct-90b",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  max_tokens=1024,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  messages=[
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  {
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "role": "user",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "content": [
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  {
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "type": "image",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "source": {
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "type": "base64",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "media_type": "image/jpeg",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "data": base64_image,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  },
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  },
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  {
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "type": "text",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "text": "Analyze this medical image. Provide: 1) Image type 2) Key findings 3) Observations 4) Next steps. Be clinical."
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  ],
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  ],
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  analysis = message.choices[0].message.content
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.markdown("---")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.subheader("VLM Analysis Results")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.write(analysis)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.success("Analysis completed!")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  except Exception as e:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.error(f"Error: {str(e)[:100]}")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.info("Ensure GROQ_API_KEY supports vision models.")
Â  Â Â 
Â  Â  st.subheader("Medical Question Answering")
Â  Â  if API_KEY:
Â  Â  Â  Â  lang = st.selectbox("Choose language", ["English", "Tamil", "Hindi", "Spanish", "French"])
Â  Â  Â  Â  question = st.text_input("Ask a medical question")
Â  Â  Â  Â Â 
Â  Â  Â  Â  if question:
Â  Â  Â  Â  Â  Â  with st.spinner("Generating answer..."):
Â  Â  Â  Â  Â  Â  Â  Â  try:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  prompt = f"Answer in {lang}: {question}"
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  response = client.chat.completions.create(
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  model="llama-3.1-8b-instant",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  messages=[{"role": "user", "content": prompt}]
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.write(response.choices[0].message.content.strip())
Â  Â  Â  Â  Â  Â  Â  Â  except Exception as e:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.error(f"Error: {str(e)}")
Â  Â  else:
Â  Â  Â  Â  st.warning("Configure GROQ_API_KEY to use this feature")

# ==================================================
# TAB 2 - MEDICAL RAG
# ==================================================
with tabs[2]:
Â  Â  st.subheader("Medical Knowledge Base RAG")
Â  Â  st.write("Retrieve medical information from knowledge base.")
Â  Â Â 
Â  Â  if API_KEY:
Â  Â  Â  Â  query = st.text_input("Enter medical query")
Â  Â  Â  Â Â 
Â  Â  Â  Â  if query:
Â  Â  Â  Â  Â  Â  with st.spinner("Retrieving information..."):
Â  Â  Â  Â  Â  Â  Â  Â  try:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  prompt = f"""Based on medical knowledge, answer this clinical query:
{query}

Provide evidence-based response with references if possible."""
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  response = client.chat.completions.create(
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  model="llama-3.1-8b-instant",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  messages=[{"role": "user", "content": prompt}]
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.success(response.choices[0].message.content.strip())
Â  Â  Â  Â  Â  Â  Â  Â  except Exception as e:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.error(f"Error: {str(e)}")
Â  Â  else:
Â  Â  Â  Â  st.warning("Configure GROQ_API_KEY to use this feature")

# ==================================================
# TAB 3 - SENTIMENT ANALYSIS
# ==================================================
with tabs[3]:
Â  Â  st.subheader("Text Sentiment Analysis")
Â  Â Â 
Â  Â  if API_KEY:
Â  Â  Â  Â  text_input = st.text_area("Enter text", height=100)
Â  Â  Â  Â Â 
Â  Â  Â  Â  if text_input:
Â  Â  Â  Â  Â  Â  with st.spinner("Analyzing..."):
Â  Â  Â  Â  Â  Â  Â  Â  try:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  prompt = f"Classify sentiment (Positive/Neutral/Negative): {text_input}"
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  response = client.chat.completions.create(
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  model="llama-3.1-8b-instant",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  messages=[{"role": "user", "content": prompt}]
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.success(response.choices[0].message.content.strip())
Â  Â  Â  Â  Â  Â  Â  Â  except Exception as e:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.error(f"Error: {str(e)}")
Â  Â  else:
Â  Â  Â  Â  st.warning("Configure GROQ_API_KEY to use this feature")

# ==================================================
# TAB 4 - TRANSLATOR
# ==================================================
with tabs[4]:
Â  Â  st.subheader("Multilingual Translator")
Â  Â Â 
Â  Â  if API_KEY:
Â  Â  Â  Â  text = st.text_input("Text to translate")
Â  Â  Â  Â  target_lang = st.selectbox("Translate to", ["Tamil", "Hindi", "Spanish", "French"])
Â  Â  Â  Â Â 
Â  Â  Â  Â  if text:
Â  Â  Â  Â  Â  Â  with st.spinner("Translating..."):
Â  Â  Â  Â  Â  Â  Â  Â  try:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  prompt = f"Translate to {target_lang}: {text}"
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  response = client.chat.completions.create(
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  model="llama-3.1-8b-instant",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  messages=[{"role": "user", "content": prompt}]
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.write(response.choices[0].message.content.strip())
Â  Â  Â  Â  Â  Â  Â  Â  except Exception as e:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.error(f"Error: {str(e)}")
Â  Â  else:
Â  Â  Â  Â  st.warning("Configure GROQ_API_KEY to use this feature")

# ==================================================
# TAB 5 - ABOUT
# ==================================================
with tabs[5]:
Â  Â  st.subheader("About HealthAI Suite")
Â  Â  st.write("""
### Mission
Provide accessible, multilingual clinical AI for healthcare professionals.

### Features
- Clinical Assessment based on vital signs
- Medical Image Analysis (VLM)
- Medical RAG for knowledge retrieval
- Medical Q&A in multiple languages
- Sentiment analysis
- Multilingual translation

### Disclaimer
This is decision-support only. Always consult healthcare professionals.

### Setup
1. Run: `python models/download_models.py`
2. Add GROQ_API_KEY to Streamlit Secrets
3. Redeploy

Version: 1.1 (Beta)
Â  Â  """)
Â  Â  st.divider()
Â  Â  st.caption("HealthAI Suite | Powered by Streamlit & Groq")
